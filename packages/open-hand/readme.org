
* Open hAND: Openreview Author Name Disambiguation

** Project Structure
*** Command line interface
*** Web Visualizer


** Requirements
MongoDB
Redis

*** Python install deps

* Author Coreference Processing
** Batch Processing
*** Fetch notes into 'shadow' Mongo db
*** Run normalizer over all shadowed notes, update db w/ cached normalized data
** For each canopy, load all papers/signatures from mongo w/given canopy
**** run predict() over single block
**** Write results back to cluster collection (cluster_id, signature_id)


*** Jaccard distance is very slow
perhaps MinHash?
*** Parallelism for sklearn prediction

https://scikit-learn.org/stable/computing/parallelism.html

** Profile viewing
https://github.com/jrfonseca/xdot.py
https://github.com/jrfonseca/gprof2dot
https://github.com/jiffyclub/snakeviz

*** numba for jit compiling?


** Issues in OpenReview data/code
*** Profile fetch by tilde id vs email yields different results
Fetch by tildeid gives one of possibly many Profiles
- then need to fetch other versions of Profiles (as listed in content.names[].username )

*** Data is inconsistent
Profile.content.dblp is string or None or empty string
history/expertise/relation start/end is number or string or None
many fields are interchangeable missing or empty string


*** tools.py does double-fetch on iterget_notes
